{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-22T16:58:29.882893Z",
     "start_time": "2025-01-22T16:58:27.346488Z"
    }
   },
   "source": [
    "\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from datasets.default_image_transform import default_image_transform\n",
    "from utils import apply_model\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "batch_size = 128\n",
    "dataset = ImageFolder(\"data/candidates\", transform=default_image_transform)\n",
    "\n",
    "model = torch.load(\"model.pickle\")\n",
    "\n",
    "print(f\"Dataset: {len(dataset):,}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Dataset: 20,227\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T17:01:04.293472800Z",
     "start_time": "2025-01-22T16:58:31.782961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = model.to(device)\n",
    "apply_model(model, dataset, range(len(dataset)), device=device)"
   ],
   "id": "f01fbc77b26dc0ad",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m----> 2\u001B[0m \u001B[43mapply_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\project-module\\utils.py:42\u001B[0m, in \u001B[0;36mapply_model\u001B[1;34m(model, test_dataset, test_indexes, device)\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_model\u001B[39m(model, test_dataset, test_indexes, device):\n\u001B[0;32m     39\u001B[0m     \u001B[38;5;66;03m# examples = test_dataset[test_indexes]\u001B[39;00m\n\u001B[0;32m     40\u001B[0m     \u001B[38;5;66;03m# true_labels = test_dataset[test_indexes]\u001B[39;00m\n\u001B[0;32m     41\u001B[0m     examples, true_labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(DataLoader(Subset(test_dataset, test_indexes), batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(test_indexes))))\n\u001B[1;32m---> 42\u001B[0m     examples \u001B[38;5;241m=\u001B[39m \u001B[43mexamples\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     43\u001B[0m     true_labels \u001B[38;5;241m=\u001B[39m true_labels\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     44\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T10:50:18.026898Z",
     "start_time": "2024-09-13T10:50:18.024170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import json\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "#\n",
    "# import pandas as pd\n",
    "#\n",
    "# annotations_dir = \"data/annotations/json\"\n",
    "# slide_df = {\"file_name\": [], \"n_annotations\": []}\n",
    "#\n",
    "# for annotations_file_name in os.listdir(annotations_dir):\n",
    "#     with open(f\"{annotations_dir}/{annotations_file_name}\") as f:\n",
    "#         annotations = json.load(f)\n",
    "#         slide_filename = Path(annotations_file_name).stem\n",
    "#         slide_df[\"file_name\"].append(slide_filename)\n",
    "#         slide_df[\"n_annotations\"].append(len(annotations))\n",
    "# slides_df = pd.DataFrame(slide_df)\n",
    "#\n",
    "# q1 = slides_df['n_annotations'].quantile(0.25)\n",
    "# median = slides_df['n_annotations'].median()\n",
    "# q3 = slides_df['n_annotations'].quantile(0.75)\n",
    "#\n",
    "#\n",
    "# # Define new categories based on quartiles\n",
    "# def categorize_quartiles(positive_regions):\n",
    "#     if positive_regions <= q1:\n",
    "#         return \"Low\"\n",
    "#     elif q1 < positive_regions <= median:\n",
    "#         return \"Medium\"\n",
    "#     elif median < positive_regions <= q3:\n",
    "#         return \"High\"\n",
    "#     else:\n",
    "#         return \"Very High\"\n",
    "#\n",
    "#\n",
    "# slides_df['category'] = slides_df['n_annotations'].apply(categorize_quartiles)\n",
    "# print(len(slides_df))\n",
    "# train_set_quartiles = pd.DataFrame()\n",
    "# test_set_quartiles = pd.DataFrame()\n",
    "#\n",
    "# for category in slides_df['category'].unique():\n",
    "#     category_slides = slides_df[slides_df['category'] == category]\n",
    "#     train = category_slides.sample(frac=0.7, random_state=42)\n",
    "#     test = category_slides.drop(train.index)\n",
    "#     train_set_quartiles = pd.concat([train_set_quartiles, train])\n",
    "#     test_set_quartiles = pd.concat([test_set_quartiles, test])\n",
    "#\n",
    "# print(train_set_quartiles)\n",
    "# print()\n",
    "# print(test_set_quartiles)\n",
    "#\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "baa2c9adce0b853f",
   "outputs": [],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
