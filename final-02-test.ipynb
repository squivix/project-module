{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T23:00:09.068703Z",
     "start_time": "2025-02-04T23:00:06.340953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from shapely import Polygon\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets.SlideSeperatedImageDataset import SlideSeperatedImageDataset\n",
    "from models.resnet import Resnet18BinaryClassifier\n",
    "from utils import divide\n"
   ],
   "id": "178fcda7c051eefd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T23:00:09.074521Z",
     "start_time": "2025-02-04T23:00:09.068703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "slides_root_dir = \"data/whole-slides/gut\"\n",
    "annotations_root_dir = \"data/annotations/json\"\n",
    "candidates_dataset_dir = \"output/candidates\"\n",
    "model_output_dir = \"output/models\""
   ],
   "id": "2692a85d7bf5fc3a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T23:00:09.414454Z",
     "start_time": "2025-02-04T23:00:09.157728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_split_dict = torch.load(f\"{model_output_dir}/data-split.pickle\")\n",
    "model = Resnet18BinaryClassifier(model=torch.load(f\"{model_output_dir}/model.pickle\"))\n",
    "train_slides = data_split_dict[\"train_slides\"]\n",
    "test_slides = data_split_dict[\"test_slides\"]"
   ],
   "id": "64c6e36f90e183bd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T23:00:09.497294Z",
     "start_time": "2025-02-04T23:00:09.420251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "model = model.to(device)\n",
    "batch_size = 256\n",
    "test_dataset = SlideSeperatedImageDataset(candidates_dataset_dir, test_slides, with_index=True)\n",
    "# test_dataset = reduce_dataset(test_dataset, discard_ratio=0)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False, )\n",
    "\n",
    "print(f\"Candidates: {len(test_dataset):,}\")"
   ],
   "id": "b2b32d9e85e9a12f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Candidates: 32,154\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T23:00:47.098471Z",
     "start_time": "2025-02-04T23:00:09.502679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "model.eval()\n",
    "indexes = []\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for i, (x_test, y_test, index) in enumerate(tqdm(iter(test_loader), desc=f\"Testing\")):\n",
    "        x_test = x_test.to(device)\n",
    "        y_test = y_test.to(device)\n",
    "        test_logits = model.forward(x_test)\n",
    "        test_loss = model.loss_function(test_logits, y_test)\n",
    "        test_preds = model.predict(test_logits)\n",
    "        indexes.append(index)\n",
    "        predictions.append(test_preds.squeeze())\n",
    "indexes = torch.cat(indexes).to(\"cpu\")\n",
    "predictions = torch.cat(predictions).to(\"cpu\")\n",
    "predicted_positives = indexes[predictions == 1]\n"
   ],
   "id": "cb40554ee9021bc3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 126/126 [00:37<00:00,  3.35it/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T23:00:47.234472Z",
     "start_time": "2025-02-04T23:00:47.184389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predicted_positive_bboxes_by_slide = {}\n",
    "for item_index in predicted_positives:\n",
    "    file_path = test_dataset.get_item_file_path(item_index)\n",
    "    file_name = Path(file_path).stem\n",
    "    slide, x_min, y_min, width, height = file_name.split(\"_\")\n",
    "    x_min, y_min, width, height = int(x_min), int(y_min), int(width), int(height)\n",
    "    if not slide in predicted_positive_bboxes_by_slide:\n",
    "        predicted_positive_bboxes_by_slide[slide] = []\n",
    "    predicted_positive_bboxes_by_slide[slide].append((x_min, y_min, width, height))"
   ],
   "id": "984d13190b9a4d21",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T23:00:48.971953Z",
     "start_time": "2025-02-04T23:00:47.280994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from itertools import product\n",
    "\n",
    "\n",
    "def calculate_iou(poly1, poly2):\n",
    "    intersection = poly1.intersection(poly2).area\n",
    "    union = poly1.union(poly2).area\n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "\n",
    "def calculate_metrics(confusion_matrix):\n",
    "    tp, fp, fn = confusion_matrix[\"TP\"], confusion_matrix[\"FP\"], confusion_matrix[\"FN\"]\n",
    "    precision = divide(tp, (tp + fp))\n",
    "    recall = divide(tp, (tp + fn))\n",
    "    f1 = divide(2 * precision * recall, (precision + recall))\n",
    "    return precision, recall, f1\n",
    "\n",
    "\n",
    "def calculate_iou_confusion_matrix(ground_truth_polygons, predicted_bboxes, iou_threshold=0.3):\n",
    "    gt_polys = [Polygon(pts).buffer(0) for pts in ground_truth_polygons]\n",
    "    pred_polys = [Polygon([(x, y), (x + w, y), (x + w, y + h), (x, y + h)]).buffer(0) for x, y, w, h in\n",
    "                  predicted_bboxes]\n",
    "\n",
    "    iou_matrix = np.zeros((len(gt_polys), len(pred_polys)))\n",
    "\n",
    "    for i, gt in enumerate(gt_polys):\n",
    "        for j, pred in enumerate(pred_polys):\n",
    "            iou_matrix[i, j] = calculate_iou(gt, pred)\n",
    "\n",
    "    matched_gt = set()\n",
    "    matched_pred = set()\n",
    "\n",
    "    for i, j in product(range(len(gt_polys)), range(len(pred_polys))):\n",
    "        if iou_matrix[i, j] > iou_threshold:\n",
    "            matched_gt.add(i)\n",
    "            matched_pred.add(j)\n",
    "\n",
    "    TP = len(matched_gt)\n",
    "    FP = len(pred_polys) - len(matched_pred)\n",
    "    FN = len(gt_polys) - len(matched_gt)\n",
    "\n",
    "    return {\n",
    "        \"TP\": TP,\n",
    "        \"FP\": FP,\n",
    "        \"FN\": FN\n",
    "    }\n",
    "\n",
    "\n",
    "total_confusion_matrix = {\n",
    "    \"TP\": 0,\n",
    "    \"FP\": 0,\n",
    "    \"FN\": 0\n",
    "}\n",
    "for slide in test_slides:\n",
    "    with open(f\"data/annotations/json/{slide}.json\") as f:\n",
    "        ground_truth_positive_annotations = json.load(f)\n",
    "    predicted_positive_bboxes = predicted_positive_bboxes_by_slide.get(slide, [])\n",
    "    confusion_matrix = calculate_iou_confusion_matrix(ground_truth_positive_annotations, predicted_positive_bboxes)\n",
    "    tp, fp, fn = confusion_matrix[\"TP\"], confusion_matrix[\"FP\"], confusion_matrix[\"FN\"]\n",
    "    precision, recall, f1 = calculate_metrics(confusion_matrix)\n",
    "\n",
    "    total_confusion_matrix[\"TP\"] += tp\n",
    "    total_confusion_matrix[\"FP\"] += fp\n",
    "    total_confusion_matrix[\"FN\"] += fn\n",
    "\n",
    "    n_ground_truth_pos = len(ground_truth_positive_annotations)\n",
    "    n_cv_candidate_pos = test_dataset.slide_to_dataset[slide].labels.sum().item()\n",
    "\n",
    "    print(\n",
    "        f\"{slide}: {n_ground_truth_pos:03d} ground truth positives, {n_cv_candidate_pos:03d} positive candidate patches, precision: {precision:.6f}, recall: {recall:.6f}, f1: {f1:.6f}\")\n",
    "total_precision, total_recall, total_f1 = calculate_metrics(total_confusion_matrix)\n",
    "print()\n",
    "print(f\"Overall: precision: {total_precision:.6f}, recall: {total_recall:.6f}, f1: {total_f1:.6f}\")\n"
   ],
   "id": "8aae2c3c89db073e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593436: 151 ground truth positives, 203 positive candidate patches, precision: 0.255507, recall: 0.384106, f1: 0.306878\n",
      "593451: 001 ground truth positives, 002 positive candidate patches, precision: 0.000000, recall: 0.000000, f1: 0.000000\n",
      "522934: 129 ground truth positives, 158 positive candidate patches, precision: 0.073394, recall: 0.310078, f1: 0.118694\n",
      "593450: 050 ground truth positives, 039 positive candidate patches, precision: 0.000000, recall: 0.000000, f1: 0.000000\n",
      "593448: 013 ground truth positives, 013 positive candidate patches, precision: 0.000000, recall: 0.000000, f1: 0.000000\n",
      "593453: 018 ground truth positives, 021 positive candidate patches, precision: 0.000000, recall: 0.000000, f1: 0.000000\n",
      "\n",
      "Overall: precision: 0.108407, recall: 0.270718, f1: 0.154818\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
