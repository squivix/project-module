{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T21:56:39.696819Z",
     "start_time": "2025-02-06T21:56:37.100898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from shapely import Polygon\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets.SlideSeperatedImageDataset import SlideSeperatedImageDataset\n",
    "from extractors.TemplateMatchExtractor import get_random_regions\n",
    "from labelers.GroundTruthLabeler import GroundTruthLabeler\n",
    "from models.resnet import Resnet18BinaryClassifier\n",
    "from utils import divide, absolute_bbox_to_relative, is_bbox_1_center_in_bbox_2, bbox_to_points, downscale_bbox, \\\n",
    "    rgb_to_bgr, downscale_points, absolute_points_to_relative, reduce_dataset, filter_points_within_bbox, \\\n",
    "    is_not_mostly_blank\n",
    "from utils import show_cv2_image"
   ],
   "id": "178fcda7c051eefd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T21:56:39.702023Z",
     "start_time": "2025-02-06T21:56:39.696819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "slides_root_dir = \"data/whole-slides/gut\"\n",
    "annotations_root_dir = \"data/annotations/json\"\n",
    "candidates_dataset_dir = \"output/candidates\"\n",
    "model_output_dir = \"output/models\""
   ],
   "id": "2692a85d7bf5fc3a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T21:56:40.122002Z",
     "start_time": "2025-02-06T21:56:39.799601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_split_dict = torch.load(f\"{model_output_dir}/data-split.pickle\")\n",
    "model = Resnet18BinaryClassifier(model=torch.load(f\"{model_output_dir}/model.pickle\"))\n",
    "train_slides = data_split_dict[\"train_slides\"]\n",
    "test_slides = data_split_dict[\"test_slides\"]\n",
    "print(\"Test slides:\", test_slides)"
   ],
   "id": "64c6e36f90e183bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test slides: {'593439', '593434', '593438', '593452', '522021', '593436', '593441'}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T21:56:40.365728Z",
     "start_time": "2025-02-06T21:56:40.127850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "model = model.to(device)\n",
    "batch_size = 256\n",
    "test_dataset = SlideSeperatedImageDataset(candidates_dataset_dir, test_slides, with_index=True)\n",
    "# test_dataset = reduce_dataset(test_dataset, discard_ratio=0.99)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False, )\n",
    "\n",
    "print(f\"Candidates: {len(test_dataset):,}\")"
   ],
   "id": "b2b32d9e85e9a12f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'output/candidates'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m      4\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m256\u001B[39m\n\u001B[1;32m----> 5\u001B[0m test_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mSlideSeperatedImageDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcandidates_dataset_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_slides\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwith_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# test_dataset = reduce_dataset(test_dataset, discard_ratio=0.99)\u001B[39;00m\n\u001B[0;32m      7\u001B[0m test_loader \u001B[38;5;241m=\u001B[39m DataLoader(test_dataset,\n\u001B[0;32m      8\u001B[0m                          batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m      9\u001B[0m                          shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, )\n",
      "File \u001B[1;32m~\\PycharmProjects\\project-module\\datasets\\SlideSeperatedImageDataset.py:15\u001B[0m, in \u001B[0;36mSlideSeperatedImageDataset.__init__\u001B[1;34m(self, root_dir, included_slides_names, transform, extension, with_index)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwith_index \u001B[38;5;241m=\u001B[39m with_index\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabels \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m---> 15\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m slide \u001B[38;5;129;01min\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mroot_dir\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m     16\u001B[0m     slide_dir \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(root_dir, slide)\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misdir(slide_dir) \u001B[38;5;129;01mor\u001B[39;00m (included_slides_names \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m slide \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m included_slides_names):\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] The system cannot find the path specified: 'output/candidates'"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T21:56:40.365728800Z",
     "start_time": "2025-02-06T21:43:56.636595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "model.eval()\n",
    "indexes = []\n",
    "probs = []\n",
    "with torch.no_grad():\n",
    "    for i, (x_test, y_test, index) in enumerate(tqdm(iter(test_loader), desc=f\"Testing\")):\n",
    "        x_test = x_test.to(device)\n",
    "        y_test = y_test.to(device)\n",
    "        test_logits = model.forward(x_test)\n",
    "        test_loss = model.loss_function(test_logits, y_test)\n",
    "        # test_preds = model.predict(test_logits)\n",
    "        indexes.append(index)\n",
    "        probs.append(test_logits.squeeze())\n",
    "indexes = torch.cat(indexes).to(\"cpu\")\n",
    "probs = torch.cat(probs).to(\"cpu\")\n"
   ],
   "id": "cb40554ee9021bc3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 398/398 [02:36<00:00,  2.54it/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T21:56:40.365728800Z",
     "start_time": "2025-02-06T21:46:33.442938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "threshold = 0.5\n",
    "predictions = probs > threshold\n",
    "predicted_positives = indexes[predictions == 1]\n",
    "predicted_positive_bboxes_by_slide = {}\n",
    "while not isinstance(test_dataset, SlideSeperatedImageDataset):\n",
    "    test_dataset = test_dataset.dataset\n",
    "\n",
    "for item_index in predicted_positives:\n",
    "    file_path = test_dataset.get_item_file_path(item_index)\n",
    "    file_name = Path(file_path).stem\n",
    "    slide, x_min, y_min, width, height = file_name.split(\"_\")\n",
    "    x_min, y_min, width, height = int(x_min), int(y_min), int(width), int(height)\n",
    "    if not slide in predicted_positive_bboxes_by_slide:\n",
    "        predicted_positive_bboxes_by_slide[slide] = []\n",
    "    predicted_positive_bboxes_by_slide[slide].append((x_min, y_min, width, height))"
   ],
   "id": "984d13190b9a4d21",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T21:56:40.365728800Z",
     "start_time": "2025-02-06T21:46:34.063474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "with open(\"temp.json\", \"w\") as f:\n",
    "    json.dump(predicted_positive_bboxes_by_slide, f)"
   ],
   "id": "9b499d3479e199a5",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T21:56:40.365728800Z",
     "start_time": "2025-02-06T21:46:34.108678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "def calculate_iou(poly, bbox):\n",
    "    intersection = poly.intersection(bbox).area\n",
    "    union = poly.union(bbox).area\n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "\n",
    "def calculate_iogt(poly, bbox):\n",
    "    intersection = poly.intersection(bbox).area\n",
    "    return intersection / poly.area if poly.area > 0 else 0\n",
    "\n",
    "\n",
    "def calculate_iopd(poly, bbox):\n",
    "    intersection = poly.intersection(bbox).area\n",
    "    return intersection / bbox.area if bbox.area > 0 else 0\n",
    "\n",
    "\n",
    "def calculate_metrics(confusion_matrix):\n",
    "    tp, fp, fn = confusion_matrix[\"TP\"], confusion_matrix[\"FP\"], confusion_matrix[\"FN\"]\n",
    "    precision = divide(tp, (tp + fp))\n",
    "    recall = divide(tp, (tp + fn))\n",
    "    f1 = divide(2 * precision * recall, (precision + recall))\n",
    "    return precision, recall, f1\n",
    "\n",
    "\n",
    "def is_matched(gt, pred, i_threshold=0.5):\n",
    "    iou = calculate_iou(gt, pred)\n",
    "    igt = calculate_iogt(gt, pred)\n",
    "    ipd = calculate_iopd(gt, pred)\n",
    "    return iou > i_threshold or igt > i_threshold or ipd > i_threshold\n",
    "\n",
    "\n",
    "def calculate_iou_confusion_matrix(ground_truth_polygons, predicted_bboxes, i_threshold=0.5):\n",
    "    gt_polys = [Polygon(pts).buffer(0) for pts in ground_truth_polygons]\n",
    "    pred_polys = [Polygon([(x, y), (x + w, y), (x + w, y + h), (x, y + h)]).buffer(0) for x, y, w, h in\n",
    "                  predicted_bboxes]\n",
    "\n",
    "    # iou_matrix = np.zeros((len(gt_polys), len(pred_polys)))\n",
    "    # igt_matrix = np.zeros((len(gt_polys), len(pred_polys)))\n",
    "    # ipd_matrix = np.zeros((len(gt_polys), len(pred_polys)))\n",
    "\n",
    "    matched_gt = set()\n",
    "    matched_pred = set()\n",
    "    for i, gt in enumerate(gt_polys):\n",
    "        for j, pred in enumerate(pred_polys):\n",
    "            if is_matched(gt, pred, i_threshold):\n",
    "                matched_gt.add(i)\n",
    "                matched_pred.add(j)\n",
    "            # iou_matrix[i, j] = calculate_iou(gt, pred)\n",
    "            # igt_matrix[i, j] = calculate_iogt(gt, pred)\n",
    "            # ipd_matrix[i, j] = calculate_iopd(gt, pred)\n",
    "\n",
    "    # for i, j in product(range(len(gt_polys)), range(len(pred_polys))):\n",
    "    #     if iou_matrix[i, j] > i_threshold or igt_matrix[i, j] > i_threshold or ipd_matrix[i, j] > i_threshold:\n",
    "    #         matched_gt.add(i)\n",
    "    #         matched_pred.add(j)\n",
    "\n",
    "    TP = len(matched_gt)\n",
    "    FP = len(pred_polys) - len(matched_pred)\n",
    "    FN = len(gt_polys) - len(matched_gt)\n",
    "\n",
    "    return {\n",
    "        \"TP\": TP,\n",
    "        \"FP\": FP,\n",
    "        \"FN\": FN\n",
    "    }\n",
    "\n",
    "\n",
    "total_confusion_matrix = {\n",
    "    \"TP\": 0,\n",
    "    \"FP\": 0,\n",
    "    \"FN\": 0\n",
    "}\n",
    "ground_truth_labeler = GroundTruthLabeler(\"data/labels/slide-annotations/all.json\",\n",
    "                                          \"data/labels/patch-classifications.csv\")\n",
    "for slide_name in test_slides:\n",
    "    ground_truth_positive_regions = ground_truth_labeler.get_positive_regions(slide_name)\n",
    "    predicted_positive_bboxes = predicted_positive_bboxes_by_slide.get(slide_name, [])\n",
    "    confusion_matrix = calculate_iou_confusion_matrix(ground_truth_positive_regions, predicted_positive_bboxes)\n",
    "    tp, fp, fn = confusion_matrix[\"TP\"], confusion_matrix[\"FP\"], confusion_matrix[\"FN\"]\n",
    "    precision, recall, f1 = calculate_metrics(confusion_matrix)\n",
    "\n",
    "    total_confusion_matrix[\"TP\"] += tp\n",
    "    total_confusion_matrix[\"FP\"] += fp\n",
    "    total_confusion_matrix[\"FN\"] += fn\n",
    "\n",
    "    n_ground_truth_pos = len(ground_truth_positive_regions)\n",
    "    n_cv_candidate_pos = test_dataset.slide_to_dataset[slide_name].labels.sum().item()\n",
    "\n",
    "    print(\n",
    "        f\"{slide_name}: {n_ground_truth_pos:03d} ground truth positives, {n_cv_candidate_pos:03d} positive candidate patches, precision: {precision:.6f}, recall: {recall:.6f}, f1: {f1:.6f}\")\n",
    "total_precision, total_recall, total_f1 = calculate_metrics(total_confusion_matrix)\n",
    "print()\n",
    "print(f\"Overall: precision: {total_precision:.6f}, recall: {total_recall:.6f}, f1: {total_f1:.6f}\")\n"
   ],
   "id": "8aae2c3c89db073e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593436: 170 ground truth positives, 215 positive candidate patches, precision: 0.509158, recall: 0.817647, f1: 0.627540\n",
      "593434: 027 ground truth positives, 030 positive candidate patches, precision: 0.169231, recall: 0.407407, f1: 0.239130\n",
      "522021: 003 ground truth positives, 003 positive candidate patches, precision: 0.000000, recall: 0.000000, f1: 0.000000\n",
      "593438: 092 ground truth positives, 130 positive candidate patches, precision: 0.099836, recall: 0.663043, f1: 0.173542\n",
      "593452: 296 ground truth positives, 331 positive candidate patches, precision: 0.062521, recall: 0.628378, f1: 0.113727\n",
      "593439: 031 ground truth positives, 027 positive candidate patches, precision: 0.045045, recall: 0.161290, f1: 0.070423\n",
      "593441: 004 ground truth positives, 000 positive candidate patches, precision: 0.000000, recall: 0.000000, f1: 0.000000\n",
      "\n",
      "Overall: precision: 0.099088, recall: 0.645265, f1: 0.171795\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T21:56:40.365728800Z",
     "start_time": "2025-02-06T21:56:31.456223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if hasattr(os, 'add_dll_directory'):\n",
    "    # Windows\n",
    "    OPENSLIDE_PATH = os.path.join(os.path.abspath(os.getcwd()), \"libs/openslide-bin-4.0.0.3-windows-x64/bin\")\n",
    "    with os.add_dll_directory(OPENSLIDE_PATH):\n",
    "        import openslide\n",
    "else:\n",
    "    import openslide\n",
    "\n",
    "\n",
    "def draw_gt_and_pred(slide_name, cell, cell_bbox, thickness=2):\n",
    "    gt_in_cell = ground_truth_labeler.get_positive_regions(slide_name, cell_bbox)\n",
    "    for ground_truth_region in gt_in_cell:\n",
    "        ground_truth_points = absolute_points_to_relative(ground_truth_region, cell_bbox)\n",
    "        ground_truth_points = downscale_points(ground_truth_points, level_downsample)\n",
    "        cv2.polylines(cell, [np.array(ground_truth_points).reshape((-1, 1, 2))], isClosed=True,\n",
    "                      color=rgb_to_bgr((255, 0, 0)), thickness=thickness)\n",
    "    predicted_positive_bboxes = predicted_positive_bboxes_by_slide.get(preview_slide_name, [])\n",
    "\n",
    "    for pred_bbox in predicted_positive_bboxes:\n",
    "        pred_points = bbox_to_points(pred_bbox)\n",
    "        is_correct = any([is_matched(gt, pred_points) for gt in gt_in_cell])\n",
    "        pred_points = filter_points_within_bbox(pred_points, cell_bbox)\n",
    "        if len(pred_points) == 0:\n",
    "            continue\n",
    "        pred_points = absolute_points_to_relative(pred_points, cell_bbox)\n",
    "        pred_points = downscale_points(pred_points, level_downsample)\n",
    "        cv2.polylines(cell, [np.array(pred_points).reshape((-1, 1, 2))], isClosed=True,\n",
    "                      color=rgb_to_bgr((0, 255, 0) if is_correct else (0, 0, 255)), thickness=thickness)\n",
    "    return cell\n",
    "\n",
    "\n",
    "test_slides = {'522021', '593436', '593439', '593441', '593438', '593434', '593452'}\n",
    "preview_slide_name = \"593452\"  # random.choice(list(test_slides))\n",
    "preview_level = 1\n",
    "preview_cell_size = 4096\n",
    "# print(ground_truth_labeler.get_positive_regions(preview_slide_name))\n",
    "slide = openslide.OpenSlide(f\"{slides_root_dir}/{preview_slide_name}.svs\")\n",
    "level_downsample = slide.level_downsamples[preview_level]\n",
    "ds_cell_size = int(preview_cell_size / level_downsample)\n",
    "full_slide_width, full_slide_height = slide.level_dimensions[0]\n",
    "\n",
    "preview_bboxes = [(x, y, preview_cell_size, preview_cell_size) for x, y in\n",
    "                  itertools.product(range(0, full_slide_width, preview_cell_size),\n",
    "                                    range(0, full_slide_height, preview_cell_size))]\n",
    "\n",
    "titles = []\n",
    "\n",
    "for i in range(len(preview_bboxes)):\n",
    "    x, y, _, _ = preview_bboxes[i]\n",
    "    preview_region = np.array(slide.read_region((x, y), preview_level, (ds_cell_size, ds_cell_size)).convert(\"RGBA\"))\n",
    "    if not is_not_mostly_blank(preview_region):\n",
    "        continue\n",
    "    preview_region = draw_gt_and_pred(preview_slide_name, preview_region, preview_bboxes[i], thickness=4)\n",
    "    show_cv2_image(preview_region)\n"
   ],
   "id": "77083ebeb73f719",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'itertools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 43\u001B[0m\n\u001B[0;32m     39\u001B[0m ds_cell_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(preview_cell_size \u001B[38;5;241m/\u001B[39m level_downsample)\n\u001B[0;32m     40\u001B[0m full_slide_width, full_slide_height \u001B[38;5;241m=\u001B[39m slide\u001B[38;5;241m.\u001B[39mlevel_dimensions[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     42\u001B[0m preview_bboxes \u001B[38;5;241m=\u001B[39m [(x, y, preview_cell_size, preview_cell_size) \u001B[38;5;28;01mfor\u001B[39;00m x, y \u001B[38;5;129;01min\u001B[39;00m\n\u001B[1;32m---> 43\u001B[0m                   \u001B[43mitertools\u001B[49m\u001B[38;5;241m.\u001B[39mproduct(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, full_slide_width, preview_cell_size),\n\u001B[0;32m     44\u001B[0m                                     \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, full_slide_height, preview_cell_size))]\n\u001B[0;32m     46\u001B[0m titles \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(preview_bboxes)):\n",
      "\u001B[1;31mNameError\u001B[0m: name 'itertools' is not defined"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
