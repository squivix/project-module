{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T11:03:46.295517Z",
     "start_time": "2024-08-12T11:03:44.591068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision.models import AlexNet_Weights\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, Subset\n",
    "\n",
    "from datasets.CustomTrainingImageDataset import generate_balanced_dataset\n",
    "from models.cnn import CnnModel\n",
    "from train import train_classifier\n",
    "from utils import plot_model_metrics\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "train_dataset, test_dataset = generate_balanced_dataset('data/DeepHP')\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True, )\n",
    "test_loader = DataLoader(test_dataset,  #Subset(test_dataset, np.arange(100)),\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True,\n",
    "                         )\n",
    "\n",
    "model = CnnModel()\n",
    "\n",
    "#CnnModel()\n",
    "print(model)\n"
   ],
   "id": "2918b0fcff38b179",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "CnnModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=valid)\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), padding=valid)\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(3, 3), padding=valid)\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(3, 3), padding=valid)\n",
      "    (11): ReLU()\n",
      "    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(3, 3), padding=valid)\n",
      "    (13): ReLU()\n",
      "    (14): Flatten(start_dim=1, end_dim=-1)\n",
      "    (15): Linear(in_features=1296, out_features=200, bias=True)\n",
      "    (16): ReLU()\n",
      "    (17): Linear(in_features=200, out_features=50, bias=True)\n",
      "    (18): ReLU()\n",
      "    (19): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T11:03:46.299172Z",
     "start_time": "2024-08-12T11:03:46.295517Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Training starts {datetime.now().isoformat()}\")",
   "id": "abba64f7aab96b14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts 2024-08-12T13:03:46.295517\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T17:30:46.156239Z",
     "start_time": "2024-08-12T11:03:46.299756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "model = model.to(device)\n",
    "model, model_metrics = train_classifier(model, train_loader, test_loader, device,\n",
    "                                        learning_rate=0.001,\n",
    "                                        weight_decay=0.0001,\n",
    "                                        max_epochs=50,\n",
    "                                        checkpoint_every=1,\n",
    "                                        eval_every=5)"
   ],
   "id": "f7966b42beaf358a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 training: 100%|██████████| 304/304 [58:55<00:00, 11.63s/it]\n",
      "Epoch 1 testing: 100%|██████████| 232/232 [11:39<00:00,  3.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/50: accuracy:0.72, loss:0.69, precision:0.00, recall:0.72, f1:0.00, epoch:0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 training: 100%|██████████| 304/304 [49:44<00:00,  9.82s/it]\n",
      "Epoch 3 training: 100%|██████████| 304/304 [49:46<00:00,  9.82s/it]\n",
      "Epoch 4 training: 100%|██████████| 304/304 [49:49<00:00,  9.83s/it]\n",
      "Epoch 5 training: 100%|██████████| 304/304 [49:47<00:00,  9.83s/it]\n",
      "Epoch 6 training: 100%|██████████| 304/304 [49:48<00:00,  9.83s/it]\n",
      "Epoch 6 testing: 100%|██████████| 232/232 [09:55<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/50: accuracy:0.28, loss:0.69, precision:0.28, recall:0.28, f1:0.44, epoch:5.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 training: 100%|██████████| 304/304 [49:47<00:00,  9.83s/it]\n",
      "Epoch 8 training:  14%|█▍        | 43/304 [07:23<44:54, 10.32s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m----> 2\u001B[0m model, model_metrics \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_classifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.001\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.0001\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mmax_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mcheckpoint_every\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43meval_every\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\project-module\\train.py:31\u001B[0m, in \u001B[0;36mtrain_classifier\u001B[1;34m(model, train_loader, test_loader, device, learning_rate, weight_decay, max_epochs, checkpoint_every, eval_every)\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (batch_x, batch_y) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(tqdm(batches, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m,\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m training\u001B[39m\u001B[38;5;124m\"\u001B[39m)):\n\u001B[0;32m     30\u001B[0m     batch_x \u001B[38;5;241m=\u001B[39m batch_x\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 31\u001B[0m     batch_y \u001B[38;5;241m=\u001B[39m \u001B[43mbatch_y\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     32\u001B[0m     logits \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mforward(batch_x)\n\u001B[0;32m     33\u001B[0m     loss \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mloss_function(logits, batch_y)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Training ends {datetime.now().isoformat()}\")\n",
    "for metric in [\"accuracy\", \"precision\", \"recall\", \"f1\"]:\n",
    "    if len(model_metrics[f\"test_{metric}\"]) > 0:\n",
    "        print(f\"Test {metric}:\", model_metrics[f\"test_{metric}\"][-1])\n",
    "\n",
    "plot_model_metrics(model_metrics)"
   ],
   "id": "1adc092f5a37613c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "torch.save(model.state_dict(), \"./model5.bin\")\n"
   ],
   "id": "387480d303a0a7ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(model_metrics)",
   "id": "6210f77ff814e0f8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
